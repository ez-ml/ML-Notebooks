{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"malware_classification_tf_idf.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"KNN\", \"Linear SVM\", \"RBF SVM\", \\\n",
    "         \"Decision Tree\", \"Random Forest\", \"MLP Classifier\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\", \"XG Boost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    XGBClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1=df['Label']\n",
    "X1=df.drop(columns=['FileName','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>8b</th>\n",
       "      <th>cc</th>\n",
       "      <th>code</th>\n",
       "      <th>data</th>\n",
       "      <th>db</th>\n",
       "      <th>dd</th>\n",
       "      <th>eax</th>\n",
       "      <th>ff</th>\n",
       "      <th>mov</th>\n",
       "      <th>rata</th>\n",
       "      <th>rdata</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647438</td>\n",
       "      <td>0.022379</td>\n",
       "      <td>0.010803</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.013119</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.077168</td>\n",
       "      <td>0.044757</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>0.019410</td>\n",
       "      <td>0.045584</td>\n",
       "      <td>0.135585</td>\n",
       "      <td>0.108807</td>\n",
       "      <td>0.081798</td>\n",
       "      <td>0.106884</td>\n",
       "      <td>0.083341</td>\n",
       "      <td>0.069435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365760</td>\n",
       "      <td>0.611620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.302425</td>\n",
       "      <td>0.019032</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>0.085415</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.048811</td>\n",
       "      <td>0.091719</td>\n",
       "      <td>0.062382</td>\n",
       "      <td>0.045594</td>\n",
       "      <td>0.142130</td>\n",
       "      <td>0.140068</td>\n",
       "      <td>0.141046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.419734</td>\n",
       "      <td>0.022625</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.010011</td>\n",
       "      <td>0.103916</td>\n",
       "      <td>0.092530</td>\n",
       "      <td>0.040762</td>\n",
       "      <td>0.123533</td>\n",
       "      <td>0.199088</td>\n",
       "      <td>0.061135</td>\n",
       "      <td>0.142441</td>\n",
       "      <td>0.065940</td>\n",
       "      <td>0.162954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.340417</td>\n",
       "      <td>0.754014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.237458</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>0.017124</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>0.085094</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.060484</td>\n",
       "      <td>0.100979</td>\n",
       "      <td>0.091358</td>\n",
       "      <td>0.018029</td>\n",
       "      <td>0.178064</td>\n",
       "      <td>0.195123</td>\n",
       "      <td>0.139903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.418235</td>\n",
       "      <td>0.037460</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.063812</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.087325</td>\n",
       "      <td>0.053584</td>\n",
       "      <td>0.063148</td>\n",
       "      <td>0.217987</td>\n",
       "      <td>0.204705</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>0.164531</td>\n",
       "      <td>0.065170</td>\n",
       "      <td>0.163720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061497</td>\n",
       "      <td>0.807603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.292281</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.678781</td>\n",
       "      <td>0.673569</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.009213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.865998</td>\n",
       "      <td>0.043174</td>\n",
       "      <td>0.024708</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.039768</td>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>0.014117</td>\n",
       "      <td>0.067391</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.316630</td>\n",
       "      <td>0.006870</td>\n",
       "      <td>0.160982</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.334678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.668594</td>\n",
       "      <td>0.661004</td>\n",
       "      <td>0.003502</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>0.006456</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.051145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.868732</td>\n",
       "      <td>0.042112</td>\n",
       "      <td>0.024526</td>\n",
       "      <td>0.021180</td>\n",
       "      <td>0.039345</td>\n",
       "      <td>0.029359</td>\n",
       "      <td>0.018765</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.065833</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.014541</td>\n",
       "      <td>0.314224</td>\n",
       "      <td>0.006335</td>\n",
       "      <td>0.157927</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.333407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.061003</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.182073</td>\n",
       "      <td>0.377356</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.905706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>821 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           00        01        02        03        04        06        10  \\\n",
       "0    0.647438  0.022379  0.010803  0.006945  0.013119  0.000773  0.077168   \n",
       "1    0.302425  0.019032  0.010945  0.008344  0.020346  0.008998  0.017775   \n",
       "2    0.419734  0.022625  0.011212  0.004338  0.025295  0.005479  0.084427   \n",
       "3    0.237458  0.023103  0.010835  0.008384  0.017643  0.006709  0.017124   \n",
       "4    0.418235  0.037460  0.009134  0.015058  0.028882  0.006302  0.063812   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "816  0.292281  0.001950  0.001802  0.001575  0.001410  0.001978  0.001673   \n",
       "817  0.865998  0.043174  0.024708  0.022167  0.039768  0.027725  0.018983   \n",
       "818  0.336364  0.003180  0.001766  0.001887  0.001926  0.001734  0.002504   \n",
       "819  0.868732  0.042112  0.024526  0.021180  0.039345  0.029359  0.018765   \n",
       "820  0.061003  0.003805  0.001682  0.001863  0.002417  0.001667  0.003375   \n",
       "\n",
       "           20        8b        cc      code      data        db        dd  \\\n",
       "0    0.044757  0.040127  0.019410  0.045584  0.135585  0.108807  0.081798   \n",
       "1    0.008430  0.085415  0.002314  0.048811  0.091719  0.062382  0.045594   \n",
       "2    0.010011  0.103916  0.092530  0.040762  0.123533  0.199088  0.061135   \n",
       "3    0.007279  0.085094  0.002497  0.060484  0.100979  0.091358  0.018029   \n",
       "4    0.010245  0.087325  0.053584  0.063148  0.217987  0.204705  0.016786   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "816  0.001478  0.002573  0.001550  0.000490  0.678781  0.673569  0.001640   \n",
       "817  0.014117  0.067391  0.034718  0.001863  0.001735  0.013363  0.316630   \n",
       "818  0.001607  0.003626  0.001496  0.003160  0.668594  0.661004  0.003502   \n",
       "819  0.012336  0.065833  0.010041  0.001649  0.003777  0.014541  0.314224   \n",
       "820  0.001799  0.004969  0.002839  0.000718  0.182073  0.377356  0.002786   \n",
       "\n",
       "          eax        ff       mov      rata     rdata      text  \n",
       "0    0.106884  0.083341  0.069435  0.000000  0.365760  0.611620  \n",
       "1    0.142130  0.140068  0.141046  0.000000  0.000000  0.907373  \n",
       "2    0.142441  0.065940  0.162954  0.000000  0.340417  0.754014  \n",
       "3    0.178064  0.195123  0.139903  0.000000  0.000000  0.907228  \n",
       "4    0.164531  0.065170  0.163720  0.000000  0.061497  0.807603  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "816  0.001744  0.002042  0.002261  0.000000  0.001470  0.009213  \n",
       "817  0.006870  0.160982  0.000250  0.000000  0.003771  0.334678  \n",
       "818  0.008713  0.006456  0.006802  0.000000  0.008104  0.051145  \n",
       "819  0.006335  0.157927  0.000234  0.000000  0.004994  0.333407  \n",
       "820  0.001895  0.008585  0.002731  0.905706  0.000000  0.016012  \n",
       "\n",
       "[821 rows x 20 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+-------+-----------+--------+\n",
      "|                | Accuracy |  F1   | Precision | Recall |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "|      KNN       |  0.901   | 0.88  |   0.889   | 0.888  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "|   Linear SVM   |  0.783   | 0.715 |   0.746   | 0.723  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "|    RBF SVM     |  0.807   | 0.782 |   0.851   | 0.776  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "| Decision Tree  |  0.776   | 0.723 |   0.749   | 0.741  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "| Random Forest  |  0.868   | 0.828 |   0.852   | 0.831  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "| MLP Classifier |  0.874   | 0.839 |   0.862   | 0.849  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "|    AdaBoost    |  0.306   | 0.207 |   0.234   | 0.279  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "|  Naive Bayes   |   0.66   | 0.617 |   0.679   | 0.654  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "|      QDA       |  0.776   | 0.689 |   0.73    | 0.708  |\n",
      "+----------------+----------+-------+-----------+--------+\n",
      "|    XG Boost    |  0.937   | 0.92  |   0.927   | 0.924  |\n",
      "+----------------+----------+-------+-----------+--------+\n"
     ]
    }
   ],
   "source": [
    "from beautifultable import BeautifulTable\n",
    "table = BeautifulTable()\n",
    "for model, name in zip(classifiers, names):    \n",
    "    # Create a pipeline that scales the data then trains a LogisticRegression classifier\n",
    "    classifier_pipeline = make_pipeline(preprocessing.StandardScaler(), model)\n",
    "\n",
    "    score_accuracy = cross_val_score(classifier_pipeline, X1, Y1, cv=10, scoring='accuracy').mean()\n",
    "    score_f1 = cross_val_score(classifier_pipeline, X1, Y1, cv=10, scoring='f1_macro').mean()\n",
    "    score_precision = cross_val_score(classifier_pipeline, X1, Y1, cv=10, scoring='precision_macro').mean()\n",
    "    score_recall = cross_val_score(classifier_pipeline, X1, Y1, cv=10, scoring='recall_macro').mean()\n",
    "\n",
    "    table.rows.append([score_accuracy,score_f1,score_precision,score_recall])\n",
    "    \n",
    "    #print_stats_metrices(name,score_accuracy,score_f1,score_precision,score_recall)\n",
    "\n",
    "table.rows.header = names\n",
    "table.columns.header = [\"Accuracy\", \"F1\", \"Precision\" , \"Recall\"]\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
